# Batchnormalization scratch python
implemented batch normalization from scratch which helps model to work well on deep neural network and for each mini batch
solving the covariance shift problem by scaling and then shifting the the activation values as moving deep in the network

its proven applying batch norm after activation is much helpful then before activation
here i have implemented batchnorm after activation  

**contributor**
@shivamjadhav2000
